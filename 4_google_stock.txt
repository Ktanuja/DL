Recurrent neural network (RNN) Use the Google stock prices dataset and design a time series
analysis and prediction system using RNN.

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.preprocessing import MinMaxScaler


data = pd.read_csv('GOOG.csv', date_parser = True)
data.tail()

data_training = data[data['Date']<'2019-01-01'].copy()
data_test = data[data['Date']>='2019-01-01'].copy()

data_training = data_training.drop(['Date', 'Adj Close'], axis = 1)

scaler = MinMaxScaler()
data_training = scaler.fit_transform(data_training)
data_training

data_training[0:10]

X_train = []
y_train = []

for i in range(60, data_training.shape[0]):
    X_train.append(data_training[i-60:i])
    y_train.append(data_training[i, 0])



X_train, y_train = np.array(X_train), np.array(y_train)

X_train.shape

from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout

regressior = Sequential()

regressior.add(LSTM(units = 60, activation = 'relu', return_sequences = True, input_shape = (X_train.shape[1], 5)))
regressior.add(Dropout(0.2))

regressior.add(LSTM(units = 60, activation = 'relu', return_sequences = True))
regressior.add(Dropout(0.2))

regressior.add(LSTM(units = 80, activation = 'relu', return_sequences = True))
regressior.add(Dropout(0.2))

regressior.add(LSTM(units = 120, activation = 'relu'))
regressior.add(Dropout(0.2))

regressior.add(Dense(units = 1))

regressior.summary()

regressior.compile(optimizer='adam', loss = 'mean_squared_error')

regressior.fit(X_train, y_train, epochs=50, batch_size=32)



data_test.head()



data_training.tail(60)


past_60_days = data_training.tail(60)

df = past_60_days.append(data_test, ignore_index = True)
df = df.drop(['Date', 'Adj Close'], axis = 1)
df.head()

inputs = scaler.transform(df)
inputs


X_test = []
y_test = []

for i in range(60, inputs.shape[0]):
    X_test.append(inputs[i-60:i])
    y_test.append(inputs[i, 0])

X_test, y_test = np.array(X_test), np.array(y_test)
X_test.shape, y_test.shape

y_pred = regressior.predict(X_test)




scaler.scale_

scale = 1/8.18605127e-04
scale


y_pred = y_pred*scale
y_test = y_test*scale



# Visualising the results
plt.figure(figsize=(14,5))
plt.plot(y_test, color = 'red', label = 'Real Google Stock Price')
plt.plot(y_pred, color = 'blue', label = 'Predicted Google Stock Price')
plt.title('Google Stock Price Prediction')
plt.xlabel('Time')
plt.ylabel('Google Stock Price')
plt.legend()
plt.show()

Sure, let's break down the code and the theoretical concepts behind it.

### Recurrent Neural Network (RNN):
Recurrent Neural Networks (RNNs) are a class of artificial neural networks where connections between nodes form directed cycles. This allows them to exhibit dynamic temporal behavior for sequences of inputs. RNNs are especially useful for processing sequences of data, such as time series data, natural language, and audio.

### Code Explanation:
1. **Data Preprocessing**: 
   - The code reads the Google stock prices dataset from a CSV file and preprocesses it. The dataset is split into training and testing sets, and features are scaled using MinMaxScaler to normalize them between 0 and 1.
2. **Model Architecture**:
   - The RNN model is defined using TensorFlow's Keras API.
   - It consists of multiple LSTM (Long Short-Term Memory) layers, which are a type of RNN designed to capture long-term dependencies in sequences.
   - Each LSTM layer is followed by a Dropout layer to prevent overfitting by randomly dropping a fraction of input units during training.
3. **Model Training**:
   - The model is compiled with an Adam optimizer and mean squared error loss function.
   - Training data (X_train) and target labels (y_train) are fed into the model for training over a specified number of epochs.
4. **Model Prediction**:
   - After training, the model is used to predict stock prices on the test data.
5. **Visualization**:
   - The predicted and actual stock prices are scaled back to their original values.
   - Finally, the real and predicted stock prices are visualized using matplotlib.

### Theoretical Concepts:
1. **LSTM (Long Short-Term Memory)**:
   - LSTMs are a type of RNN designed to overcome the vanishing gradient problem and better capture long-term dependencies in sequences.
   - They consist of a cell state that runs through time steps, with gates (input, output, forget gates) controlling the flow of information.
   - LSTMs can selectively remember or forget information over arbitrary time intervals, making them suitable for time series prediction tasks.
2. **Dropout**:
   - Dropout is a regularization technique used to prevent overfitting in neural networks.
   - It works by randomly setting a fraction of input units to zero during training, which helps the model to generalize better to unseen data.
3. **MinMaxScaler**:
   - MinMaxScaler scales and translates each feature individually to a given range, often between 0 and 1.
   - It's commonly used for normalization in machine learning tasks, ensuring that all features contribute equally to the learning process.

Overall, the code implements an RNN-based time series analysis and prediction system for Google stock prices, leveraging LSTM layers to capture temporal patterns in the data.





