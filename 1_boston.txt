//Problem statement: Linear regression by using Deep Neural network: Implement Boston housing price prediction
problem by Linear regression using Deep Neural network. Use Boston House price prediction
dataset.

//code
import pandas as pd
!pip install scikit-learn==1.1

from sklearn.datasets import load_boston
import pandas as pd
boston_dataset = load_boston()
df = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)
df['MEDV'] = boston_dataset.target
df.head(n=10)

df.columns

from sklearn.model_selection import train_test_split
X = df.loc[:, df.columns != 'MEDV']
y = df.loc[:, df.columns == 'MEDV']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)

from sklearn.preprocessing import MinMaxScaler
mms = MinMaxScaler()
mms.fit(X_train)
X_train = mms.transform(X_train)
X_test = mms.transform(X_test)


from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
model = Sequential()
model.add(Dense(128, input_shape=(13, ), activation='relu', name='dense_1'))
model.add(Dense(64, activation='relu', name='dense_2'))
model.add(Dense(1, activation='linear', name='dense_output'))
model.compile(optimizer='adam', loss='mse', metrics=['mae'])
model.summary()

history = model.fit(X_train, y_train, epochs=100, validation_split=0.05, verbose = 1)

mse_nn, mae_nn = model.evaluate(X_test, y_test)
print('Mean squared error on test data: ', mse_nn)
print('Mean absolute error on test data: ', mae_nn)




Theory
1. **Importing Libraries and Dataset:**
   - Importing necessary libraries like pandas and scikit-learn.
   - Loading the Boston housing dataset using scikit-learn.

2. **Data Preprocessing:**
   - Creating a DataFrame using the loaded dataset.
   - Separating features and target variable ('MEDV') from the dataset.
   - Splitting the data into training and testing sets.

3. **Normalization:**
   - Normalizing the features using MinMaxScaler to scale them between 0 and 1. This helps in faster convergence during training.

4. **Building the Neural Network Model:**
   - Creating a Sequential model using Keras.
   - Adding layers:
     - Input layer with 128 neurons and 'relu' activation function.
     - Hidden layer with 64 neurons and 'relu' activation function.
     - Output layer with 1 neuron for regression and 'linear' activation function.
   - Compiling the model with 'adam' optimizer, mean squared error (MSE) loss function, and mean absolute error (MAE) metric.

5. **Model Training:**
   - Fitting the model to the training data for 100 epochs with a validation split of 5%.

6. **Model Evaluation:**
   - Evaluating the model's performance on the test data using mean squared error (MSE) and mean absolute error (MAE).

The provided code implements a deep neural network for linear regression to predict Boston housing prices. It preprocesses the data, builds a neural network model, trains the model, and evaluates its performance. The model's performance is assessed using metrics such as mean squared error (MSE) and mean absolute error (MAE) on the test data.

Sure, let's break down each term along with its use in the context of the provided code:

1. **Linear Regression**:
   - Linear regression is a statistical method used to model the relationship between a dependent variable (target) and one or more independent variables (features) by fitting a linear equation to the observed data. In this code, linear regression is implemented using a deep neural network model to predict Boston housing prices based on features like crime rate, number of rooms, etc.

2. **scikit-learn**:
   - Scikit-learn is a popular machine learning library in Python that provides simple and efficient tools for data mining and data analysis. It offers various algorithms for classification, regression, clustering, dimensionality reduction, and more. In this code, scikit-learn is used for loading the Boston housing dataset and for data preprocessing tasks like splitting the dataset into training and testing sets.

3. **pandas**:
   - Pandas is a powerful open-source data analysis and manipulation library in Python. It provides data structures and functions to work with structured data, such as data frames (similar to tables in databases) and series (similar to arrays). In this code, pandas is used to create a DataFrame from the Boston housing dataset, which makes it easier to manipulate and analyze the data.

4. **MEDV**:
   - MEDV stands for "Median Value" and represents the target variable in the Boston housing dataset. It refers to the median value of owner-occupied homes in thousands of dollars. In this code, 'MEDV' is the target variable that we aim to predict using linear regression.

5. **Normalization**:
   - Normalization is a preprocessing technique used to rescale numeric features to a similar scale, typically between 0 and 1. It helps in preventing features with larger magnitudes from dominating the model training process and ensures faster convergence. In this code, MinMaxScaler from scikit-learn is used for normalization of the input features.

6. **Keras**:
   - Keras is a high-level neural networks API written in Python. It allows for easy and fast experimentation with deep learning models and provides a user-friendly interface to build, train, and deploy neural networks. In this code, Keras is used to define and train the deep neural network model for linear regression.

7. **'adam' optimizer**:
   - Adam (Adaptive Moment Estimation) is an optimization algorithm commonly used for training deep learning models. It combines ideas from RMSprop and Momentum algorithms to achieve good performance on a wide range of deep learning tasks. In this code, 'adam' optimizer is used to minimize the mean squared error loss during training.

8. **Mean Squared Error (MSE) Loss Function**:
   - MSE is a commonly used loss function for regression problems. It calculates the average of the squared differences between the predicted values and the actual values. In this code, MSE loss function is used to measure the difference between the predicted and actual housing prices during training.

9. **Mean Absolute Error (MAE) Metric**:
   - MAE is another metric commonly used for regression problems. It calculates the average of the absolute differences between the predicted values and the actual values. In this code, MAE metric is used to evaluate the performance of the model on the test data.

Sure, let's delve into each of these terms:

1. **Data Mining**:
   - Data mining is the process of discovering patterns, trends, correlations, or insights from large datasets using various methods such as statistical analysis, machine learning, and artificial intelligence. The goal of data mining is to extract useful and actionable information from data to support decision-making, identify opportunities, or solve problems. It involves several steps including data preprocessing, exploration, modeling, and interpretation of results.

2. **Classification**:
   - Classification is a supervised learning task in machine learning where the goal is to predict the categorical class label of an instance based on its features. In classification, the algorithm learns from labeled training data to classify new unseen instances into one of the predefined classes or categories. Common algorithms used for classification include decision trees, random forests, support vector machines, and neural networks. Applications of classification include email spam detection, sentiment analysis, disease diagnosis, and image recognition.

3. **Clustering**:
   - Clustering is an unsupervised learning task in machine learning where the goal is to group similar instances or data points into clusters based on their features, without prior knowledge of class labels. In clustering, the algorithm automatically discovers the inherent structure or patterns in the data by partitioning it into groups such that instances within the same group are more similar to each other than to those in other groups. Common clustering algorithms include K-means, hierarchical clustering, DBSCAN, and Gaussian mixture models. Applications of clustering include customer segmentation, document clustering, anomaly detection, and image segmentation.

